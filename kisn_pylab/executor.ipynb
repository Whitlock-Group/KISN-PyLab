{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A pipeline for recording, processing & successfully merging e-phys, IMU and tracking data (v3.0.0).\n",
    "### author: github/bartulem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **[Step 0]** Considerations before, during and after conducting the experiments.\n",
    "\n",
    "1. Set up [SpikeGLX](https://billkarsh.github.io/SpikeGLX/) to accommodate your specific recording configuration.\n",
    "2. Turn on and calibrate the IMU before every session (system calibration does not need to be 3, but others do before the rat is plugged on; time readings should not have duplicates either).\n",
    "3. Open Motive.\n",
    "- Check whether the system is calibrated (continuous calibration should be on).\n",
    "- If necessary, for each camera change strobe light settings to continuous light.\n",
    "- Check that the rigid bodies for the head & arena LEDs exist (this enables on-line automatic labeling).\n",
    "- Check whether the acquisition directory is the correct one.\n",
    "- Check whether camera 1 is recording in MJPG/greyscale mode.\n",
    "4. Put three circular markers on the back of the animal and plug it on.\n",
    "5. Conduct the recording.\n",
    "- In the NPX, tracking and IMU acquisition programs, you should see the microcontroller-generated random LED pulses.\n",
    "- Start acquiring the IPI sync data.\n",
    "- Start recording in SpikeGLX.\n",
    "- Start acquiring data on the IMU.\n",
    "- Start recording in Motive.\n",
    "- Keep it going for some time (e.g. 20-25 min).\n",
    "- Stop recording in Motive.\n",
    "- Stop acquiring data on the IMU.\n",
    "- Stop recording in SpikeGLX.\n",
    "- Stop acquiring the IPI sync data.\n",
    "6. It's good practice to label the back points immediately in Motive (the head & LEDs should be labeled already, if step 3d was implemented) and export the data in a .csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 1]** Concatenate Neuropixel recording sessions. This step is *optional*, you can skip it if you are interested in only one session.\n",
    "\n",
    "As a necessary input, you determine:\n",
    "1. the directories where the NPX .bin files are (all associated files should be in the same directory; also, make sure they're named in a way that will order them properly)\n",
    "2. the desired paths to the future merged files\n",
    "3. the desired paths to the future .pkl files\n",
    "\n",
    "As elective inputs, note that you have the option to set:\n",
    "1. file_type (concatenate lf or ap files; defaults to ap)\n",
    "2. cmd_prompt (whether to do the merging through the terminal/cmd prompt; defaults to True)\n",
    "3. nchan (the number of channels on the probe; defaults to 385)\n",
    "4. npx_sampling_rate (sampling rate of the NPX system; defaults to 3e4)\n",
    "\n",
    "Thus, multiple unrelated data streams can be processed sequentially.\n",
    "\n",
    "The outputs of the code are as follows:\n",
    "1. new_file_name (the newly created concatenated file; saved as .bin file)\n",
    "2. pkl_len (information about change-points of the concatenated sessions; saved as .pkl file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kisn_pylab import concatenate\n",
    "\n",
    "file_directories = [r'A:\\store\\Bartul\\neuropixel\\26525_kavorka_RH\\190620_distal\\spikes_imec0']\n",
    "new_file_names = [r'A:\\store\\Bartul\\neuropixel\\26525_kavorka_RH\\190620_distal\\spikes_imec0\\190620_distal_all_g0_t0.imec0.ap.bin']\n",
    "pkl_lengths = [r'A:\\store\\Bartul\\neuropixel\\26525_kavorka_RH\\190620_distal\\spikes_imec0\\190620_distal_all_g0_t0.imec0.ap.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_dir, new_file_name, pkl_len in zip(file_directories, new_file_names, pkl_lengths):\n",
    "    concatClass = concatenate.Concat(file_dir, new_file_name, pkl_len)\n",
    "    concatClass.concat_npx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 2]** Run Kilosort2 through Python.\n",
    "\n",
    "This step assumes you are happy with *everything* in the config file. If you need to modify anything, either the code needs to change or you complete this step in Matlab.\n",
    "\n",
    "If this doesn't bother you, then you should do the following:\n",
    "1. Download/clone [Kilosort2](https://github.com/MouseLand/Kilosort2) and set up the config, master and CUDA files accordingly.\n",
    "2. Install [matlab engine](https://www.mathworks.com/help/matlab/matlab_external/install-the-matlab-engine-for-python.html) (only tried this as an admin, but might work otherwise as well).\n",
    "3. Kilosort2 runs on all the .bin files in the given directory below. Make sure that this is what you want.\n",
    "4. Don't use my Kilosort2 directory, but rather your own (created when completing point 1).\n",
    "5. Modify the \"master\" file such that it takes .bin file directory as input.\n",
    "6. Set the file and Kilosort2 directories, and run the cell below.\n",
    "\n",
    "!NB: While Kilosort2 is running, it's a good opportunity to label the tracking data if you haven't done so already!\n",
    "\n",
    "As necessary inputs, note that you have to set:\n",
    "1. file_dir (the absolute path to the directories the binary files are in)\n",
    "2. kilosort2_dir (the absolute path to the directory the Kilosort2 code is in)\n",
    "\n",
    "Thus, multiple unrelated data streams can be processed sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kisn_pylab import kilosort\n",
    "\n",
    "file_dirs = [r'A:\\store\\Bartul\\neuropixel\\26525_kavorka_RH\\190620_intermediate\\spikes_imec0']\n",
    "kilosort2_dir = r'A:\\group\\bartulm\\Kilosort2-master'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for file_dir in file_dirs:\n",
    "    kilosort.run_kilosort(file_dir, kilosort2_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **[Step 3]** Arbitrate what is noise and what are clusters in Phy.\n",
    "1. Install Phy: [Phy v2.0](https://github.com/cortex-lab/phy)\n",
    "2. Navigate to the directory where Kilosort2 results were saved, open powershell and type \"cmd\", followed by \"activate phy2\", followed by \"phy template-gui params.py\".\n",
    "3. Complete the manual curation ([Phy tutorial](https://phy.readthedocs.io/en/latest/)) and save your work.\n",
    "\n",
    "!NB: You can delete the .phy directory after you've completed the manual curation!"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **[Step 4]** Compute cluster quality measures for 'good' and 'MUA' clusters.\n",
    "\n",
    "This step assumes manual curation was completed (!NB: noise was labeled as noise!), in order to compute quality measures for non-noise clusters.\n",
    "\n",
    "As a necessary input, you determine:\n",
    "1. the directories where the Kilosort2 output files are\n",
    "\n",
    "As elective inputs, note that you have the option to set:\n",
    "1. nchan (the number of channels on the probe; defaults to 385)\n",
    "2. npx_sampling_rate (the sampling rate of the NPX system; defaults to 3e4)\n",
    "3. num_channels_to_compare (the number of channels to look at around peak channel, must be odd; defaults to 13)\n",
    "4. max_spikes_for_cluster (the maximum number of spikes to analyze; defaults to 1000)\n",
    "5. perform_waveforms (yey or ney on the waveform metrics; defaults to True)\n",
    "6. perform_isiv (yey or ney on the isi_violations computation; defaults to True)\n",
    "7. perform_mahalanobis (yey or ney on the mahalanobis_metrics; defaults to True)\n",
    "8. perform_nnm (yey or ney on the nearest_neighbors_metrics; defaults to True)\n",
    "9. perform_lda (yey or ney on the LDA metric; defaults to True)\n",
    "10. re_categorize (yey or ney on re-categorizing clusters based on contamination features; defaults to True)\n",
    "11. save_quality_measures (yey or ney on saving the cluster_quality_measures.json file; defaults to True)\n",
    "12. min_spikes (the minimum number of spikes a cluster should have to be saved; defaults to 100)\n",
    "13. max_good_isi (the maximum acceptable FP ISI metric in order for the cluster to be considered 'good'; defaults to .02)\n",
    "14. max_good_contam (the maximum acceptable ContamPct in order for the cluster to be considered 'good'; defaults to 10)\n",
    "\n",
    "!NB: The .bin spike data file must be in the directory with the output files!\n",
    "\n",
    "Thus, multiple unrelated data streams can be processed sequentially.\n",
    "\n",
    "The outputs of the code are as follows:\n",
    "1. cluster_quality_measures (a dictionary with cluster quality measures for each non-noise cluster; saved as .json file)\n",
    "2. cluster_group (a DataFrame with information about cluster type; overwritten .tsv file if re_categorize was chosen)\n",
    "3. cluster_info (a DataFrame with different information about all clusters; overwritten .tsv file if re_categorize was chosen)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kisn_pylab import clusters2categories\n",
    "\n",
    "kilosort_output_dirs = [r'A:\\store\\Bartul\\neuropixel\\26472_roy_LH\\270520_intermediate\\spikes_imec0']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for kilosort_output_dir in kilosort_output_dirs:\n",
    "    qualityClass = clusters2categories.ClusterQuality(kilosort_output_dir=kilosort_output_dir)\n",
    "    qualityClass.compute_quality_measures()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **[Step 5]** Estimate surface channel from LFP data.\n",
    "\n",
    "As necessary inputs, note that you have to set:\n",
    "1. lfp_dir (the absolute path to the directory the LFP binary file is in)\n",
    "\n",
    "As elective inputs, note that you have the option to set:\n",
    "1. nchan (the number of channels on the probe; defaults to 385)\n",
    "2. lfp_sampling_frequency (the sampling rate of the LPF acquisition; defaults to 2.5e3)\n",
    "3. lfp_gain_setting (the amplifier gain for the LFP band; defaults to 250)\n",
    "4. smoothing_width (Gaussian smoothing parameter to reduce channel-to-channel noise; defaults to 5)\n",
    "5. power_threshold (ignore threshold crossings if power is above this level (indicates channels are in the brain); defaults to 2.5)\n",
    "6. diff_threshold (threshold to detect large increases in power at brain surface; defaults to -0.06)\n",
    "7. freq_range (frequency band for detecting power increases; defaults to list((0, 10)))\n",
    "8. channel_range (channels assumed to be out of brain, but in saline; defaults to False)\n",
    "9. nfft (length of FFT used for calculations; defaults to 4096)\n",
    "10. n_passes (number of times to compute offset and surface channel; defaults to 5)\n",
    "11. skip_s_per_pass (number of seconds between data chunks used on each pass; defaults to 5)\n",
    "12. max_freq (maximum frequency to plot; defaults to 150)\n",
    "13. reference_channel (reference channel on probe (if in use); defaults to False.\n",
    "14. to_plot (yey or ney on the result figure; defaults to True)\n",
    "15. colormap (the colormap of choice for the figure; defaults to 'afmhot')\n",
    "16. save_plot (yey or ney on saving the figure; defaults to False)\n",
    "17. fig_format (the format of the saved figure; defaults to 'png')\n",
    "\n",
    "One file should be processed at a time, with adequate checks performed.\n",
    "\n",
    "The output of the code is as follows:\n",
    "1. figure (a figure summarizing the results of seeking the surface channel with LFP data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kisn_pylab import surface\n",
    "\n",
    "lfp_dir = r'D:\\SGL_DATA\\26504_jacopo_150620\\s1_1900_light_intermediate_g0\\s1_1900_light_intermediate_g0_imec0'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ssClass = surface.SeekSurface(lfp_dir)\n",
    "ssClass.find_surface_channel(diff_threshold=-0.06, save_plot=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 6]** Read in the sync events (make sure the PC has enough memory to run this, say 64Gb RAM) and put them in separate .txt files.\n",
    "\n",
    "If you haven't done so already, label the tracked rigid bodies and marker sets in Motive (read the tutorial if you need) and export the data:\n",
    "1. File > Export Tracking Data.\n",
    "2. The following options need to be OFF: (1) Unlabeled markers, (2) Rigid Bodies, (3) Rigid Body markers, (4) Bones, (5) Bone markers.\n",
    "3. Click \"Export\" and you should have created a .csv file (it may take ~1 minute, depending on the length of the recording).\n",
    "\n",
    "As necessary inputs, you determine:\n",
    "1. the list with the files whose sync events you'd like to read (in practice this would be the imec0 and imec1 files for a given recording session)\n",
    "2. the absolute path of the future sync .pkl file\n",
    "\n",
    "As elective inputs, note that you have the option to set:\n",
    "1. nchan (the number of channels on the probe; defaults to 385)\n",
    "2. sync_chan (the specific sync port channel on the probe; defaults to 385)\n",
    "3. track_file (the absolute path to the tracking file for that session; defaults to 'eldiablomuerte')\n",
    "4. imu_file (the absolute path to the IMU file for that session; defaults to 'eldiablomuerte')\n",
    "5. sync_ipi_file (the absolute path to the sync IPI data .txt file; defaults to 'eldiablomuerte')\n",
    "6. sync_led_duration (the duration of ON time for sync LEDs; defaults to 250 (ms))\n",
    "7. sync_led_error (the possible sample error in the duration of ON time for sync LEDs; defaults to 50 (ms))\n",
    "8. ground_probe (in a dual probe setting, the probe the other is synced to - if you only have imec1, this needs to be set to 1; defaults to 0)\n",
    "9. frame_rate (the tracking camera frame rate for that session; defaults to 120)\n",
    "10. npx_sampling_rate (the sampling rate of the NPX system; defaults to 3e4)\n",
    "11. sync_sequence (the length of the sequence the LED events should be matched across data streams; defaults to 10)\n",
    "12. sample_error (the time the presumed IMEC/IMU LEDs could be allowed to err around; defaults to 30 (ms))\n",
    "13. which_imu_time (the IMU time to be used in the analyses, loop.starttime (0) or sample.time (1); defaults to 1)\n",
    "\n",
    "Therefore, you proceed one recording session at a time.\n",
    "\n",
    "The outputs of the code are as follows:\n",
    "1. track_file (the corrected and LED-shortened tracing data; saved as a separate .csv file if track_file was given).\n",
    "2. imu_file (the IMU data; saved as .pkl file if IMU .txt data file was given).\n",
    "3. sync_df (the sync data; saved as .pkl file if either of the two above were given)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kisn_pylab import reader\n",
    "\n",
    "npx_files = [r'D:\\SGL_DATA\\26504_jacopo_150620\\s4_2025_light_intermediate_g0\\s4_2025_light_intermediate_g0_imec0\\s4_2025_light_intermediate_g0_t0.imec0.ap.bin']\n",
    "sync_df = r'A:\\store\\Bartul\\neuropixel\\26504_jacopo_LH\\150620_intermediate\\26504_jacopo_150620_2025_intermediate_s4_light\\sync_df_150620_s4_intermediate.pkl'\n",
    "track_file = r'A:\\store\\Bartul\\neuropixel\\26504_jacopo_LH\\150620_intermediate\\26504_jacopo_150620_2025_intermediate_s4_light\\tracking\\Take 2020-06-15 08.24.44 PM (1).csv'\n",
    "imu_file = r'A:\\store\\Bartul\\neuropixel\\26504_jacopo_LH\\150620_intermediate\\26504_jacopo_150620_2025_intermediate_s4_light\\IMU\\CoolTerm Capture 2020-06-15 20-24-41.txt'\n",
    "sync_ipi_file = r'A:\\store\\Bartul\\neuropixel\\26504_jacopo_LH\\150620_intermediate\\26504_jacopo_150620_2025_intermediate_s4_light\\IMU\\CoolTerm Capture 2020-06-15 20-24-41.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "readClass = reader.EventReader(npx_files, sync_df)\n",
    "readClass.read_se(track_file=track_file, imu_file=imu_file, sync_ipi_file=sync_ipi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 7]** Load the sync data from the .pkl file(s) and analyze how well the tracking/IMU data are synced with NPX data.\n",
    "\n",
    "Before running this step, make sure you have [plotly](https://plotly.com/python/getting-started/?utm_source=mailchimp-jan-2015&utm_medium=email&utm_campaign=generalemail-jan2015&utm_term=bubble-chart) installed.\n",
    "\n",
    "As a necessary input, you determine:\n",
    "1. the sync_df .pkl files\n",
    "\n",
    "As elective inputs, note that you have the option to set:\n",
    "1. npx_sampling_rate (sampling rate of the NPX system; defaults to 3e4)\n",
    "2. to_plot (plot or not to plot y_test and y_test_prediction statistics; defaults to False)\n",
    "3. ground_probe (in a dual probe setting, the probe the other is synced to; defaults to 0)\n",
    "4. imu_files (the list of absolute paths to imu_pkl files that contain the raw IMU data; defaults to 0)\n",
    "5. which_imu_time (the IMU time to be used in the analyses, loop.starttime (0) or sample.time (1); defaults to 1)\n",
    "\n",
    "Thus, multiple files can be processed in sequence.\n",
    "\n",
    "The imu_files should be ordered such that the first sync file corresponds to the IMU file of the same session, and so forth.\n",
    "\n",
    "The output of the code is as follows:\n",
    "1. sync_df (the sync data; overwritten .pkl file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kisn_pylab import synchronize\n",
    "\n",
    "sync_pkls = [r'A:\\store\\Bartul\\neuropixel\\26504_jacopo_LH\\150620_intermediate\\26504_jacopo_150620_2025_intermediate_s4_light\\sync_df_150620_s4_intermediate.pkl']\n",
    "imu_files = [r'A:\\store\\Bartul\\neuropixel\\26504_jacopo_LH\\150620_intermediate\\26504_jacopo_150620_2025_intermediate_s4_light\\IMU\\CoolTerm Capture 2020-06-15 20-24-41.pkl']\n",
    "to_plot = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "syncClass = synchronize.Sync(sync_pkls)\n",
    "syncClass.estimate_sync_quality(to_plot=to_plot, imu_files=imu_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **[Step 8]** Split clusters back into individual sessions and get spike times. This step should be completed irrespective of the number of sorted sessions.\n",
    "\n",
    "As necessary inputs, you determine:\n",
    "1. the_dirs (a list of directories where Kilosort2 results are stored for each recording probe)\n",
    "2. sync_pkls (paths to as many sync .pkl files as there are recording sessions)\n",
    "\n",
    "As elective inputs, note that you have the option to set:\n",
    "1. nchan (the number of channels on the probe; defaults to 385)\n",
    "2. one_session (whether you have only one session; defaults to True)\n",
    "3. min_spikes (the minimum number of spikes in one session to consider the cluster worthy of saving; defaults to 100)\n",
    "4. npx_sampling_rate (sampling rate of the NPX system; defaults to 3e4)\n",
    "5. ground_probe (in a dual probe setting, the probe the other is synced to; defaults to 0)\n",
    "6. to_plot (plot or not to plot y_test and y_test_prediction statistics; defaults to False)\n",
    "7. pkl_lengths (.pkl files that have information about where concatenated files were stitched together; defaults to 0)\n",
    "8. print_details (whether or not to print details about spikes in every individual cluster; defaults to False)\n",
    "9. important_cluster_groups (the list of relevant cluster groups you want to analyze, should be 'good' and 'mua'; defaults to list('good'))\n",
    "10. eliminate_duplicates (whether or not to eliminate duplicate spikes; defaults to True)\n",
    "11. min_isi (threshold for duplicate spikes in seconds; defaults to 0)\n",
    "12. switch_clock (convert each sample spike time to time as measured by the IPI generator; defaults to False)\n",
    "\n",
    "!NB: make sure each directory has the imec ID in the name!\n",
    "\n",
    "Therefore, you proceed one recording day at a time.\n",
    "\n",
    "The outputs of the code are as follows:\n",
    "1. spike times (arrays that contain spike times (in seconds); saved as .mat files in a separate directory)\n",
    "2. cluster_groups_information (information about which cluster belongs to 'good' or 'MUA' categories; saved as .json file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kisn_pylab import spikes2sessions\n",
    "\n",
    "the_dirs = [r'A:\\store\\Bartul\\neuropixel\\26471_johnjohn_RH\\210520\\spikes_imec0']\n",
    "sync_pkls = [r'A:\\store\\Bartul\\neuropixel\\sync_df_215020_s1_distal.pkl',\n",
    "             r'A:\\store\\Bartul\\neuropixel\\sync_df_215020_s2_distal.pkl',\n",
    "             r'A:\\store\\Bartul\\neuropixel\\sync_df_215020_s3_distal.pkl',\n",
    "             r'A:\\store\\Bartul\\neuropixel\\sync_df_215020_s4_distal.pkl']\n",
    "pkl_lengths = [r'A:\\store\\Bartul\\neuropixel\\26471_johnjohn_RH\\210520\\spikes_imec0\\210520_distal_all_g0_t0.imec0.ap.pkl']\n",
    "one_session = False\n",
    "important_cluster_groups = ['good', 'mua']\n",
    "min_spikes = 100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sstClass = spikes2sessions.ExtractSpikes(the_dirs, sync_pkls)\n",
    "sstClass.split_clusters(one_session=one_session, min_spikes=min_spikes, pkl_lengths=pkl_lengths, important_cluster_groups=important_cluster_groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **[Step 9]** Create .pkl file for GUI.\n",
    "\n",
    "As necessary inputs, you determine:\n",
    "1. the absolute paths where the .csv (tracking) files are (tracking files with the appendage \"final\" should be used!)\n",
    "2. the absolute paths where the .pkl (sync event) files are\n",
    "\n",
    "As elective inputs, note that you have the option to set:\n",
    "1. frame_rate (you set it manually, otherwise it's read from the sync .pkl file)\n",
    "2. npx_sampling_rate (sampling rate of the NPX system; defaults to 3e4)\n",
    "3. ground_probe (in a dual probe setting, the probe the other is synced to; defaults to 0)\n",
    "4. session_timestamps (whether to take session timestamps (True) for start/stop recording or tracking (False); defaults to True)\n",
    "\n",
    "Thus, multiple files can be processed in sequence. Every GUI .pkl file is saved to the same directory as the tracking .csv file.\n",
    "\n",
    "!NB: The rat-cam is meant to be used for the raw tracking video, which should be exported to match the sequence from the start of first to the start of the last LED event!\n",
    "\n",
    "The output of the code is as follows:\n",
    "1. final (dictionary with the tracking data and other information; saved as .pkl file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kisn_pylab import motive2GUI\n",
    "\n",
    "the_csvs = [r'A:\\store\\Bartul\\neuropixel\\26504_jacopo_LH\\150620_intermediate\\26504_jacopo_150620_2025_intermediate_s4_light\\tracking\\Take 2020-06-15 08.24.44 PM (1)_final.csv']\n",
    "sync_pkls = [r'A:\\store\\Bartul\\neuropixel\\26504_jacopo_LH\\150620_intermediate\\26504_jacopo_150620_2025_intermediate_s4_light\\sync_df_150620_s4_intermediate.pkl']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for the_csv, sync_pkl in zip(the_csvs, sync_pkls):\n",
    "    mtgClass = motive2GUI.Transformer(the_csv, sync_pkl)\n",
    "    mtgClass.csv_to_pkl()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **[Step 10]** Finish processing the tracking data and create .mat files in the GUI.\n",
    "\n",
    "1. create the head in the GUI (trackedpointdata_V3_5_LEDs.py version)\n",
    "2. load the spiking .mat files\n",
    "3. export everything as a .mat file"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **[Step 11]** Re-head .mat files according to a template file.\n",
    "\n",
    "As necessary inputs, you determine:\n",
    "1. the absolute paths where the template .mat (tracking + spikes) file is\n",
    "2. the absolute paths where the other .mat files are (!NB: the rigid body placement should be same as in the template file!)\n",
    "\n",
    "Every processed .mat file is saved to the same directory as the original .mat file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from kisn_pylab import rehead\n",
    "\n",
    "template_file = r'C:\\Users\\bartulm\\Downloads\\test_bens_code\\bruno_060520_s1_light.mat'\n",
    "other_files = [r'C:\\Users\\bartulm\\Downloads\\test_bens_code\\bruno_060520_s2_light.mat']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reheaderClass = rehead.ReHead(template_file, other_files)\n",
    "reheaderClass.conduct_transformations()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}